# Spoken2Sign Pipeline (49-Landmark Sign Language Skeleton)

A clean, modular, SLRT-style Python pipeline for generating sign-language skeleton animations (49 MediaPipe Holistic landmarks) from spoken text.

---

## ğŸŒ Overview

This project implements a functional **Spoken-to-Sign (S2S)** demonstration system:

**English text â†’ Gloss sequence â†’ Preprocessed keypoints â†’ Skeleton animation (MP4)**

It uses:

- **49 MediaPipe Holistic landmarks**  
  - 21 left hand  
  - 21 right hand  
  - 7 upper body  
- Phoenix-style gloss mapping (GLOSS_0 â€“ GLOSS_19)  
- Clean py modules & scripts  
- Interpolation, velocity filtering, and smoothing  
- A layered renderer for human-readable sign skeletons  

This structure makes the system extensible for future training, evaluation, or integration with SLRT-style models.

---

## ğŸ“ Repository Structure

```
spoken2sign-pipeline/
â”‚
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ loader.py          # Load PKL keypoints & gloss CSV
â”‚   â”œâ”€â”€ preprocess.py      # Velocity filtering, interpolation, smoothing
â”‚   â”œâ”€â”€ translate.py       # English â†’ gloss sequence
â”‚   â”œâ”€â”€ builder.py         # Gloss â†’ keypoint sequence builder
â”‚   â”œâ”€â”€ renderer.py        # Layered skeleton renderer (MP4 output)
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_pipeline.py    # Main pipeline: text â†’ MP4 animation
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ default.yaml       # File paths & rendering settings
â”‚
â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ README.md          # Instructions to place PKL & CSV files
â”‚
â”œâ”€â”€ output/
â”‚   â””â”€â”€ .gitkeep           # Rendered videos saved here
â”‚
â””â”€â”€ README.md
```

---

## ğŸ”§ Installation

Clone the repository:

```bash
git clone https://github.com/<your-username>/spoken2sign-pipeline
cd spoken2sign-pipeline
```

Install required packages (Colab already has them):

```bash
pip install numpy matplotlib scipy pyyaml
```

---

## ğŸ“‚ Dataset Setup

Place the following files inside **datasets/**:

- `holistic_49_keypoints.pkl`
- `gloss_map.csv`

These files contain the pre-extracted 49-keypoint sequences for each gloss (Phoenix-small subset).

Then, edit the paths inside:

```
configs/default.yaml
```

---

## â–¶ï¸ Run the Pipeline

From the project root:

```bash
python scripts/run_pipeline.py
```

Videos will be saved in:

```
output/
```

The pipeline generates animations for test sentences such as:

- HELLO WORLD  
- GOOD MORNING  
- THANK YOU  
- WHAT IS YOUR NAME  
- STOP PLEASE  
- HAPPY MORNING  

---

## ğŸ§  Pipeline Stages

### **1ï¸âƒ£ Load Data**
`loader.py`

Loads PKL keypoints + gloss map.

---

### **2ï¸âƒ£ Preprocess Sequence**
`clean_sequence()` in `preprocess.py`

âœ” Removes unrealistic jumps  
âœ” Interpolates missing frames  
âœ” Smooths hands and upper-body joints  

---

### **3ï¸âƒ£ Text â†’ Gloss Mapping**
`translate.py`

Maps English words to gloss IDs.

---

### **4ï¸âƒ£ Build Sequence**
`builder.py`

Creates a continuous sequence with transitions between glosses.

---

### **5ï¸âƒ£ Render Animation**
`renderer.py`

Outputs clean, layered skeleton animations:

- Grey body  
- Red hands  
- Blue joints  

---

## ğŸ¯ Purpose

This repository provides:

- A reproducible Spoken-to-Sign demonstration pipeline  
- Proper research-grade project structuring  
- A clean transition away from notebooks to py scripts  
- A foundation for integrating SLRT-style models in future work  

---

## ğŸ™Œ Credits

- MediaPipe Holistic  
- Phoenix-2014-T Gloss Dataset  
- SLRT (Fangyun Wei et al.) â€” for structural inspiration  

---
